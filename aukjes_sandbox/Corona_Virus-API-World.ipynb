{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import pprint\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_files(corona_file):\n",
    "\n",
    "    corona_url = \"https://github.com/globalcitizen/2019-wuhan-coronavirus-data/blob/master/\" + corona_file\n",
    "    print(\"now processing: \" + corona_url)\n",
    "\n",
    "    new_date = corona_file[22:26]+\"-\"+corona_file[26:28]+\"-\"+corona_file[28:30]\n",
    "    print(new_date)\n",
    "\n",
    "    response = requests.get(corona_url)\n",
    "    time.sleep(10)\n",
    "    print(response)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    my_text = soup.find_all('td', class_='blob-code blob-code-inner js-file-line', attrs={\"id\":\"LC1\"})\n",
    "\n",
    "#     print(my_text)\n",
    "    limit = 100\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        for index, d_fl in enumerate(my_text):\n",
    "        #     print(d_fl.text)\n",
    "            my_scrape_file = d_fl.text\n",
    "            if index==limit:\n",
    "                break\n",
    "\n",
    "#         print(my_scrape_file)        \n",
    "\n",
    "        my_series = eval(my_scrape_file)\n",
    "       \n",
    "        my_scrape_df = pd.DataFrame(my_series)\n",
    "        \n",
    "        provinces = pd.read_csv(\"static/master_data/provinces.csv\")\n",
    "        df_provinces = pd.DataFrame(provinces).set_index(\"provinceShortName\")\n",
    "#         df_provinces\n",
    "#         df_data = pd.read_csv(\"data/df_2020-01-26.csv\")\n",
    "        my_scrape_df = pd.merge(df_provinces, my_scrape_df, on=(\"provinceShortName\"))\n",
    "        my_scrape_df = my_scrape_df[['american_name','provinceName',\"provinceShortName\", \"confirmedCount\", \"suspectedCount\",'curedCount','deadCount']]\n",
    "        my_scrape_df\n",
    "        \n",
    "#         my_scrape_df = my_scrape_df[['provinceName', \"provinceShortName\", \"confirmedCount\", \"suspectedCount\",'curedCount','deadCount', 'cities']]\n",
    "        my_scrape_df['date'] = new_date\n",
    "        output_path = os.path.join(\"static/data\", \"df_\" + new_date + \".csv\")\n",
    "        my_scrape_df.to_csv(output_path)\n",
    "#         my_scrape_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_file = open('static/data/urls_to_data_files.txt')\n",
    "try:\n",
    "    for i, line in enumerate(input_file):\n",
    "        # Remove hard return from line-string\n",
    "        line = line[:-1]\n",
    "        print(\"---\"+line+\"---\")\n",
    "        corona_file = line\n",
    "        process_all_files(corona_file)\n",
    "        print(line)\n",
    "finally:\n",
    "    input_file.close()\n",
    "    print(\"Done\")\n",
    "# print f\"{0} line(s) printed\".format(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geojson(date, filename):\n",
    "#     df_data = pd.read_csv(\"static/data/df_\" + date + \".csv\")\n",
    "    df_data = pd.read_csv(\"static/data/\" + filename)\n",
    "\n",
    "    # df_json = (df_data).to_json()\n",
    "    df_data = df_data.set_index(\"provinceName\")\n",
    "#     df_data\n",
    "\n",
    "    json_df = pd.read_json('static/geojsons/china.json', encoding='UTF-8')\n",
    "    json_df_feat = pd.DataFrame(json_df.features)\n",
    "\n",
    "#     with open('static/geojsons/china2.json', encoding='UTF-8') as f:\n",
    "#       china_json = json.load(f)\n",
    "# #     pprint.pprint(china_json)\n",
    "\n",
    "    geo_dict = {}\n",
    "    geo_string = \"\"\n",
    "\n",
    "    for index, row in json_df_feat.iterrows():\n",
    "        try:\n",
    "            str_feat_1 = (\"{\\\"type\\\": \\\"Feature\\\",\")\n",
    "\n",
    "            prop_name = row['features']['properties']['name']\n",
    "\n",
    "            prop_american_name = df_data.loc[prop_name,\"american_name\"]\n",
    "            prop_confirmedCount = df_data.loc[prop_name,\"confirmedCount\"]\n",
    "            prop_suspectedCount = df_data.loc[prop_name,\"suspectedCount\"]\n",
    "            prop_curedCount = df_data.loc[prop_name,\"curedCount\"]\n",
    "            prop_deadCount = df_data.loc[prop_name,\"deadCount\"]    \n",
    "            prop_date = df_data.loc[prop_name,\"date\"]\n",
    "\n",
    "            str_prop_double_quotes = str(row['features']['properties'])\n",
    "            str_prop_double_quotes = str_prop_double_quotes.replace(\"\\'\",\"\\\"\")\n",
    "\n",
    "            str_prop_1 = (\"\\\"properties\\\" : \" + str_prop_double_quotes + \"\\\",\")[:-3]\n",
    "            str_prop_2 = (\",\\\"american_name\\\" : \\\"\" + prop_american_name + \"\\\",\")\n",
    "            str_prop_3 = (\"\\\"confirmedCount\\\" : \\\"\" + str(prop_confirmedCount) + \"\\\",\")\n",
    "            str_prop_4 = (\"\\\"suspectedCount\\\" : \\\"\" + str(prop_suspectedCount) + \"\\\",\")\n",
    "            str_prop_5 = (\"\\\"curedCount\\\" : \\\"\" + str(prop_curedCount) + \"\\\",\")\n",
    "            str_prop_6 = (\"\\\"deadCount\\\" : \\\"\" + str(prop_deadCount) + \"\\\",\")\n",
    "            str_prop_7 = (\"\\\"date\\\" : \\\"\" + prop_date + \"\\\"},\")\n",
    "\n",
    "            str_prop_all  = str_prop_1 + str_prop_2 + str_prop_3 + str_prop_4 + str_prop_5 + str_prop_6 + str_prop_7\n",
    "        #     print(str_prop_all)\n",
    "        #     print('=============================')    \n",
    "        #     print(row['features']['geometry'])\n",
    "            str_geom_1 = (\"\\\"geometry\\\":\" + str(row['features']['geometry']) + \"},\")\n",
    "            str_geom_1 = str_geom_1.replace(\"\\'\",\"\\\"\")\n",
    "        #     print(str_geom_1)\n",
    "        #     print('=============================')\n",
    "\n",
    "            str_for_each_province = (str_feat_1)+(str_prop_all)+(str_geom_1)\n",
    "        #     print(str_for_each_province)\n",
    "            geo_string = geo_string + (str_for_each_province)\n",
    "        except:\n",
    "            str_feat_1 = (\"{\\\"type\\\": \\\"Feature\\\",\")\n",
    "\n",
    "            prop_name = row['features']['properties']['name']\n",
    "\n",
    "            prop_american_name = \"\"\n",
    "            prop_confirmedCount = 0\n",
    "            prop_suspectedCount = 0\n",
    "            prop_curedCount = 0\n",
    "            prop_deadCount = 0    \n",
    "            prop_date = date\n",
    "\n",
    "            str_prop_double_quotes = str(row['features']['properties'])\n",
    "            str_prop_double_quotes = str_prop_double_quotes.replace(\"\\'\",\"\\\"\")\n",
    "\n",
    "            str_prop_1 = (\"\\\"properties\\\" : \" + str_prop_double_quotes + \"\\\",\")[:-3]\n",
    "            str_prop_2 = (\",\\\"american_name\\\" : \\\"\" + prop_american_name + \"\\\",\")\n",
    "            str_prop_3 = (\"\\\"confirmedCount\\\" : \\\"\" + str(prop_confirmedCount) + \"\\\",\")\n",
    "            str_prop_4 = (\"\\\"suspectedCount\\\" : \\\"\" + str(prop_suspectedCount) + \"\\\",\")\n",
    "            str_prop_5 = (\"\\\"curedCount\\\" : \\\"\" + str(prop_curedCount) + \"\\\",\")\n",
    "            str_prop_6 = (\"\\\"deadCount\\\" : \\\"\" + str(prop_deadCount) + \"\\\",\")\n",
    "            str_prop_7 = (\"\\\"date\\\" : \\\"\" + prop_date + \"\\\"},\")\n",
    "\n",
    "            str_prop_all  = str_prop_1 + str_prop_2 + str_prop_3 + str_prop_4 + str_prop_5 + str_prop_6 + str_prop_7\n",
    "        #     print(str_prop_all)\n",
    "        #     print('=============================')    \n",
    "        #     print(row['features']['geometry'])\n",
    "            str_geom_1 = (\"\\\"geometry\\\":\" + str(row['features']['geometry']) + \"},\")\n",
    "            str_geom_1 = str_geom_1.replace(\"\\'\",\"\\\"\")\n",
    "        #     print(str_geom_1)\n",
    "        #     print('=============================')\n",
    "\n",
    "            str_for_each_province = (str_feat_1)+(str_prop_all)+(str_geom_1)\n",
    "        #     print(str_for_each_province)\n",
    "            geo_string = geo_string + (str_for_each_province)\n",
    "    pre_fix = \"{\\\"type\\\": \\\"FeatureCollection\\\", \\\"features\\\": [\"\n",
    "    post_fix = \"]}\"\n",
    "\n",
    "    total_string = pre_fix + geo_string[:-1] + post_fix\n",
    "\n",
    "    print(total_string)\n",
    "    output_path = os.path.join(\"static/geojsons\", date + \".json\")\n",
    "    with open(output_path, \"w\", encoding='UTF-8') as text_file:\n",
    "        text_file.write(total_string)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For later. Loop through all the files created\n",
    "for filename in os.listdir(\"static/data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "         # print(os.path.join(directory, filename))\n",
    "        print(filename)\n",
    "        date = filename[3:13]\n",
    "        print(date)\n",
    "        create_geojson(date, filename)\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/17/20</th>\n",
       "      <th>2/18/20</th>\n",
       "      <th>2/19/20</th>\n",
       "      <th>2/20/20</th>\n",
       "      <th>2/21/20</th>\n",
       "      <th>2/22/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/24/20</th>\n",
       "      <th>2/25/20</th>\n",
       "      <th>2/26/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>973</td>\n",
       "      <td>982</td>\n",
       "      <td>986</td>\n",
       "      <td>987</td>\n",
       "      <td>988</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>387</td>\n",
       "      <td>393</td>\n",
       "      <td>395</td>\n",
       "      <td>396</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>553</td>\n",
       "      <td>555</td>\n",
       "      <td>560</td>\n",
       "      <td>567</td>\n",
       "      <td>572</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>117.9895</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>292</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region       Lat      Long  1/22/20  1/23/20  \\\n",
       "0          Anhui  Mainland China  31.82571  117.2264        1        9   \n",
       "1        Beijing  Mainland China  40.18238  116.4142       14       22   \n",
       "2      Chongqing  Mainland China  30.05718  107.8740        6        9   \n",
       "3         Fujian  Mainland China  26.07783  117.9895        1        5   \n",
       "4          Gansu  Mainland China  36.06110  103.8343        0        2   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/17/20  2/18/20  2/19/20  \\\n",
       "0       15       39       60       70  ...      973      982      986   \n",
       "1       36       41       68       80  ...      381      387      393   \n",
       "2       27       57       75      110  ...      553      555      560   \n",
       "3       10       18       35       59  ...      290      292      293   \n",
       "4        2        4        7       14  ...       91       91       91   \n",
       "\n",
       "   2/20/20  2/21/20  2/22/20  2/23/20  2/24/20  2/25/20  2/26/20  \n",
       "0      987      988      989      989      989      989      989  \n",
       "1      395      396      399      399      399      400      400  \n",
       "2      567      572      573      575      576      576      576  \n",
       "3      293      293      293      293      293      294      294  \n",
       "4       91       91       91       91       91       91       91  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data from 3 different data source\n",
    "confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv'\n",
    "df_confirmed = pd.read_csv(confirmed_url)\n",
    "cured_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'\n",
    "df_cured = pd.read_csv(cured_url)\n",
    "death_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv'\n",
    "df_death = pd.read_csv(death_url)\n",
    "# total_columns = len(df_death.columns)\n",
    "# df_death.head()\n",
    "# tables.describe()\n",
    "df_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>117.9895</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region       Lat      Long     Date  Value  \\\n",
       "0          Anhui  Mainland China  31.82571  117.2264  1/22/20      1   \n",
       "1        Beijing  Mainland China  40.18238  116.4142  1/22/20     14   \n",
       "2      Chongqing  Mainland China  30.05718  107.8740  1/22/20      6   \n",
       "3         Fujian  Mainland China  26.07783  117.9895  1/22/20      1   \n",
       "4          Gansu  Mainland China  36.06110  103.8343  1/22/20      0   \n",
       "\n",
       "    new_date  \n",
       "0 2020-01-22  \n",
       "1 2020-01-22  \n",
       "2 2020-01-22  \n",
       "3 2020-01-22  \n",
       "4 2020-01-22  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unique rows by moving date column to row level for all Confirmed cases\n",
    "df_confirmed_long = df_confirmed.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_confirmed_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_confirmed_original.csv\")\n",
    "df_confirmed.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Cured cases\n",
    "df_cured_long = df_cured.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_cured_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_cured_original.csv\")\n",
    "df_cured.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Death cases\n",
    "df_death_long = df_death.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_death_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_death_original.csv\")\n",
    "df_death.to_csv(output_path)\n",
    "\n",
    "df_confirmed_long.head()\n",
    "df_confirmed_long[\"new_date\"] = pd.to_datetime(df_confirmed_long['Date'])\n",
    "# df_confirmed_long.drop(['Date'], axis=1)\n",
    "\n",
    "# df_temp=df_death_long[df_death_long[\"Province/State\"].isnull()]\n",
    "# df_temp.head()\n",
    "df_confirmed_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Province/State isn't filled, use the country value instead\n",
    "\n",
    "df_confirmed_long[\"Province/State\"].fillna(df_confirmed_long[\"Country/Region\"], inplace=True)\n",
    "df_confirmed_long = df_confirmed_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\", \"Date\":\"date\", \"Value\": \"conf_count\"})\n",
    "\n",
    "df_cured_long[\"Province/State\"].fillna(df_cured_long[\"Country/Region\"], inplace=True)\n",
    "df_cured_long = df_cured_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"cured_count\"})\n",
    "\n",
    "df_death_long[\"Province/State\"].fillna(df_death_long[\"Country/Region\"], inplace=True)\n",
    "df_death_long = df_death_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"dead_count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_confirmed_long.loc[(df_confirmed_long.country == 'Mainland China'),'country']='China'\n",
    "df_confirmed_long = df_confirmed_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_cured_long.loc[(df_cured_long.country == 'Mainland China'),'country']='China'\n",
    "df_cured_long = df_cured_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_death_long.loc[(df_death_long.country == 'Mainland China'),'country']='China'\n",
    "df_death_long = df_death_long.set_index(['date', 'american_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>conf_count</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>american_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1/22/20</th>\n",
       "      <th>Anhui</th>\n",
       "      <td>China</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>China</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chongqing</th>\n",
       "      <td>China</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fujian</th>\n",
       "      <td>China</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>117.9895</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gansu</th>\n",
       "      <td>China</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2/26/20</th>\n",
       "      <th>Georgia</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>42.31540</td>\n",
       "      <td>43.3569</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>Greece</td>\n",
       "      <td>39.07420</td>\n",
       "      <td>21.8243</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Macedonia</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>41.60860</td>\n",
       "      <td>21.7453</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>Norway</td>\n",
       "      <td>60.47200</td>\n",
       "      <td>8.4689</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>Romania</td>\n",
       "      <td>45.94320</td>\n",
       "      <td>24.9668</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 country       lat      long  conf_count  \\\n",
       "date    american_name                                                      \n",
       "1/22/20 Anhui                      China  31.82571  117.2264           1   \n",
       "        Beijing                    China  40.18238  116.4142          14   \n",
       "        Chongqing                  China  30.05718  107.8740           6   \n",
       "        Fujian                     China  26.07783  117.9895           1   \n",
       "        Gansu                      China  36.06110  103.8343           0   \n",
       "...                                  ...       ...       ...         ...   \n",
       "2/26/20 Georgia                  Georgia  42.31540   43.3569           1   \n",
       "        Greece                    Greece  39.07420   21.8243           1   \n",
       "        North Macedonia  North Macedonia  41.60860   21.7453           1   \n",
       "        Norway                    Norway  60.47200    8.4689           1   \n",
       "        Romania                  Romania  45.94320   24.9668           1   \n",
       "\n",
       "                          new_date  \n",
       "date    american_name               \n",
       "1/22/20 Anhui           2020-01-22  \n",
       "        Beijing         2020-01-22  \n",
       "        Chongqing       2020-01-22  \n",
       "        Fujian          2020-01-22  \n",
       "        Gansu           2020-01-22  \n",
       "...                            ...  \n",
       "2/26/20 Georgia         2020-02-26  \n",
       "        Greece          2020-02-26  \n",
       "        North Macedonia 2020-02-26  \n",
       "        Norway          2020-02-26  \n",
       "        Romania         2020-02-26  \n",
       "\n",
       "[3636 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_confirmed_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american_name</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>conf_count</th>\n",
       "      <th>date</th>\n",
       "      <th>cured_count</th>\n",
       "      <th>dead_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>117.9895</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  american_name country       lat      long  conf_count       date  \\\n",
       "0         Anhui   China  31.82571  117.2264           1 2020-01-22   \n",
       "1       Beijing   China  40.18238  116.4142          14 2020-01-22   \n",
       "2     Chongqing   China  30.05718  107.8740           6 2020-01-22   \n",
       "3        Fujian   China  26.07783  117.9895           1 2020-01-22   \n",
       "4         Gansu   China  36.06110  103.8343           0 2020-01-22   \n",
       "\n",
       "   cured_count  dead_count  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_merged = pd.merge(df_confirmed_long, df_cured_long, how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_death_long,how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "df_merged = df_merged.reset_index()\n",
    "df_merged = df_merged.drop(['date'], axis=1)\n",
    "df_merged = df_merged.rename(columns={\"new_date\":\"date\"})\n",
    "\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_all.csv\")\n",
    "df_merged.to_csv(output_path)\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
