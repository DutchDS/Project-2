{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import pprint\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geojson(date):\n",
    "    df_countries_by_day = df_merged[(df_merged.date==date)]\n",
    "    df_data = df_countries_by_day.groupby(['country','country_2']).agg({'conf_count':'sum', 'cured_count':'sum', 'dead_count':'sum'}).reset_index()\n",
    "    df_data = df_data.set_index('country')\n",
    "    \n",
    "                                          \n",
    "    json_df = pd.read_json('static/world_geojsons/world.json', encoding='UTF-8')\n",
    "    json_df_feat = pd.DataFrame(json_df.features)\n",
    "\n",
    "    geo_dict = {}\n",
    "    geo_string = \"\"\n",
    "\n",
    "    for index, row in json_df_feat.iterrows():\n",
    "#         print(row['features']['properties']['ADMIN'])\n",
    "        try:\n",
    "            str_feat_1 = (\"{\\\"type\\\": \\\"Feature\\\",\")\n",
    "\n",
    "            prop_name = row['features']['properties']['ADMIN']\n",
    "#             print(prop_name)\n",
    "\n",
    "            prop_american_name = df_data.loc[prop_name,\"country_2\"]\n",
    "#             print(\"AM_NAME\", prop_american_name)\n",
    "            prop_confirmedCount = df_data.loc[prop_name,\"conf_count\"]\n",
    "#             print(\"Conf_C\", prop_confirmedCount)\n",
    "            prop_suspectedCount = 0\n",
    "            prop_curedCount = df_data.loc[prop_name,\"cured_count\"]\n",
    "#             print(\"Cured_C\", prop_curedCount)\n",
    "            prop_deadCount = df_data.loc[prop_name,\"dead_count\"]    \n",
    "#             print(\"Dead_C\", prop_deadCount)\n",
    "            prop_date = date\n",
    "#             print(\"Date:\", prop_date)\n",
    "\n",
    "            str_prop_double_quotes = str(row['features']['properties'])\n",
    "            str_prop_double_quotes = str_prop_double_quotes.replace(\"\\'\",\"\\\"\")\n",
    "\n",
    "            str_prop_1 = (\"\\\"properties\\\" : \" + str_prop_double_quotes + \"\\\",\")[:-3]\n",
    "            str_prop_2 = (\",\\\"american_name\\\" : \\\"\" + prop_american_name + \"\\\",\")\n",
    "            str_prop_3 = (\"\\\"confirmedCount\\\" : \\\"\" + str(prop_confirmedCount) + \"\\\",\")\n",
    "            str_prop_4 = (\"\\\"suspectedCount\\\" : \\\"\" + str(prop_suspectedCount) + \"\\\",\")\n",
    "            str_prop_5 = (\"\\\"curedCount\\\" : \\\"\" + str(prop_curedCount) + \"\\\",\")\n",
    "            str_prop_6 = (\"\\\"deadCount\\\" : \\\"\" + str(prop_deadCount) + \"\\\",\")\n",
    "            str_prop_7 = (\"\\\"date\\\" : \\\"\" + prop_date + \"\\\"},\")\n",
    "\n",
    "            str_prop_all  = str_prop_1 + str_prop_2 + str_prop_3 + str_prop_4 + str_prop_5 + str_prop_6 + str_prop_7\n",
    "#             print(str_prop_all)\n",
    "        #     print('=============================')    \n",
    "        #     print(row['features']['geometry'])\n",
    "            str_geom_1 = (\"\\\"geometry\\\":\" + str(row['features']['geometry']) + \"},\")\n",
    "            str_geom_1 = str_geom_1.replace(\"\\'\",\"\\\"\")\n",
    "        #     print(str_geom_1)\n",
    "        #     print('=============================')\n",
    "\n",
    "            str_for_each_province = (str_feat_1)+(str_prop_all)+(str_geom_1)\n",
    "        #     print(str_for_each_province)\n",
    "            geo_string = geo_string + (str_for_each_province)\n",
    "        except:\n",
    "            str_feat_1 = (\"{\\\"type\\\": \\\"Feature\\\",\")\n",
    "\n",
    "            prop_name = row['features']['properties']['ADMIN']\n",
    "\n",
    "            prop_american_name = \"\"\n",
    "            prop_confirmedCount = 0\n",
    "            prop_suspectedCount = 0\n",
    "            prop_curedCount = 0\n",
    "            prop_deadCount = 0  \n",
    "            prop_date = date\n",
    "\n",
    "            str_prop_double_quotes = str(row['features']['properties'])\n",
    "            str_prop_double_quotes = str_prop_double_quotes.replace(\"\\'\",\"\\\"\")\n",
    "\n",
    "            str_prop_1 = (\"\\\"properties\\\" : \" + str_prop_double_quotes + \"\\\",\")[:-3]\n",
    "            str_prop_2 = (\",\\\"american_name\\\" : \\\"\" + prop_american_name + \"\\\",\")\n",
    "            str_prop_3 = (\"\\\"confirmedCount\\\" : \\\"\" + str(prop_confirmedCount) + \"\\\",\")\n",
    "            str_prop_4 = (\"\\\"suspectedCount\\\" : \\\"\" + str(prop_suspectedCount) + \"\\\",\")\n",
    "            str_prop_5 = (\"\\\"curedCount\\\" : \\\"\" + str(prop_curedCount) + \"\\\",\")\n",
    "            str_prop_6 = (\"\\\"deadCount\\\" : \\\"\" + str(prop_deadCount) + \"\\\",\")\n",
    "            str_prop_7 = (\"\\\"date\\\" : \\\"\" + prop_date + \"\\\"},\")\n",
    "\n",
    "            str_prop_all  = str_prop_1 + str_prop_2 + str_prop_3 + str_prop_4 + str_prop_5 + str_prop_6 + str_prop_7\n",
    "        #     print(str_prop_all)\n",
    "        #     print('=============================')    \n",
    "        #     print(row['features']['geometry'])\n",
    "            str_geom_1 = (\"\\\"geometry\\\":\" + str(row['features']['geometry']) + \"},\")\n",
    "            str_geom_1 = str_geom_1.replace(\"\\'\",\"\\\"\")\n",
    "        #     print(str_geom_1)\n",
    "        #     print('=============================')\n",
    "\n",
    "            str_for_each_province = (str_feat_1)+(str_prop_all)+(str_geom_1)\n",
    "        #     print(str_for_each_province)\n",
    "            geo_string = geo_string + (str_for_each_province)\n",
    "    pre_fix = \"{\\\"type\\\": \\\"FeatureCollection\\\", \\\"features\\\": [\"\n",
    "    post_fix = \"]}\"\n",
    "\n",
    "    total_string = pre_fix + geo_string[:-1] + post_fix\n",
    "\n",
    "#     print(total_string)\n",
    "    output_path = os.path.join(\"static/world_geojsons\", date + \".json\")\n",
    "    with open(output_path, \"w\", encoding='UTF-8') as text_file:\n",
    "        text_file.write(total_string)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/18/20</th>\n",
       "      <th>2/19/20</th>\n",
       "      <th>2/20/20</th>\n",
       "      <th>2/21/20</th>\n",
       "      <th>2/22/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/24/20</th>\n",
       "      <th>2/25/20</th>\n",
       "      <th>2/26/20</th>\n",
       "      <th>2/27/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>982</td>\n",
       "      <td>986</td>\n",
       "      <td>987</td>\n",
       "      <td>988</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>387</td>\n",
       "      <td>393</td>\n",
       "      <td>395</td>\n",
       "      <td>396</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>555</td>\n",
       "      <td>560</td>\n",
       "      <td>567</td>\n",
       "      <td>572</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>292</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long  1/22/20  1/23/20  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264        1        9   \n",
       "1        Beijing  Mainland China  40.1824  116.4142       14       22   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740        6        9   \n",
       "3         Fujian  Mainland China  26.0789  117.9874        1        5   \n",
       "4          Gansu  Mainland China  36.0611  103.8343        0        2   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/18/20  2/19/20  2/20/20  \\\n",
       "0       15       39       60       70  ...      982      986      987   \n",
       "1       36       41       68       80  ...      387      393      395   \n",
       "2       27       57       75      110  ...      555      560      567   \n",
       "3       10       18       35       59  ...      292      293      293   \n",
       "4        2        4        7       14  ...       91       91       91   \n",
       "\n",
       "   2/21/20  2/22/20  2/23/20  2/24/20  2/25/20  2/26/20  2/27/20  \n",
       "0      988      989      989      989      989      989      989  \n",
       "1      396      399      399      399      400      400      410  \n",
       "2      572      573      575      576      576      576      576  \n",
       "3      293      293      293      293      294      294      296  \n",
       "4       91       91       91       91       91       91       91  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data from 3 different data source\n",
    "confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv'\n",
    "df_confirmed = pd.read_csv(confirmed_url)\n",
    "cured_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'\n",
    "df_cured = pd.read_csv(cured_url)\n",
    "death_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv'\n",
    "df_death = pd.read_csv(death_url)\n",
    "# total_columns = len(df_death.columns)\n",
    "# df_death.head()\n",
    "# tables.describe()\n",
    "df_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long     Date  Value   new_date\n",
       "0          Anhui  Mainland China  31.8257  117.2264  1/22/20      1 2020-01-22\n",
       "1        Beijing  Mainland China  40.1824  116.4142  1/22/20     14 2020-01-22\n",
       "2      Chongqing  Mainland China  30.0572  107.8740  1/22/20      6 2020-01-22\n",
       "3         Fujian  Mainland China  26.0789  117.9874  1/22/20      1 2020-01-22\n",
       "4          Gansu  Mainland China  36.0611  103.8343  1/22/20      0 2020-01-22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unique rows by moving date column to row level for all Confirmed cases\n",
    "df_confirmed_long = df_confirmed.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_confirmed_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_confirmed_original.csv\")\n",
    "df_confirmed.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Cured cases\n",
    "df_cured_long = df_cured.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_cured_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_cured_original.csv\")\n",
    "df_cured.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Death cases\n",
    "df_death_long = df_death.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_death_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_death_original.csv\")\n",
    "df_death.to_csv(output_path)\n",
    "\n",
    "df_confirmed_long.head()\n",
    "df_confirmed_long[\"new_date\"] = pd.to_datetime(df_confirmed_long['Date'])\n",
    "# df_confirmed_long.drop(['Date'], axis=1)\n",
    "\n",
    "# df_temp=df_death_long[df_death_long[\"Province/State\"].isnull()]\n",
    "# df_temp.head()\n",
    "df_confirmed_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Province/State isn't filled, use the country value instead\n",
    "\n",
    "df_confirmed_long[\"Province/State\"].fillna(df_confirmed_long[\"Country/Region\"], inplace=True)\n",
    "df_confirmed_long = df_confirmed_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\", \"Date\":\"date\", \"Value\": \"conf_count\"})\n",
    "\n",
    "df_cured_long[\"Province/State\"].fillna(df_cured_long[\"Country/Region\"], inplace=True)\n",
    "df_cured_long = df_cured_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"cured_count\"})\n",
    "\n",
    "df_death_long[\"Province/State\"].fillna(df_death_long[\"Country/Region\"], inplace=True)\n",
    "df_death_long = df_death_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"dead_count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_confirmed_long.loc[(df_confirmed_long.country == 'Mainland China'),'country']='China'\n",
    "df_confirmed_long = df_confirmed_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_cured_long.loc[(df_cured_long.country == 'Mainland China'),'country']='China'\n",
    "df_cured_long = df_cured_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_death_long.loc[(df_death_long.country == 'Mainland China'),'country']='China'\n",
    "df_death_long = df_death_long.set_index(['date', 'american_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american_name</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>conf_count</th>\n",
       "      <th>date</th>\n",
       "      <th>cured_count</th>\n",
       "      <th>dead_count</th>\n",
       "      <th>country_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  american_name country      lat      long  conf_count       date  \\\n",
       "0         Anhui   China  31.8257  117.2264           1 2020-01-22   \n",
       "1       Beijing   China  40.1824  116.4142          14 2020-01-22   \n",
       "2     Chongqing   China  30.0572  107.8740           6 2020-01-22   \n",
       "3        Fujian   China  26.0789  117.9874           1 2020-01-22   \n",
       "4         Gansu   China  36.0611  103.8343           0 2020-01-22   \n",
       "\n",
       "   cured_count  dead_count country_2  \n",
       "0            0           0     China  \n",
       "1            0           0     China  \n",
       "2            0           0     China  \n",
       "3            0           0     China  \n",
       "4            0           0     China  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_merged = pd.merge(df_confirmed_long, df_cured_long, how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_death_long,how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "df_merged = df_merged.reset_index()\n",
    "df_merged = df_merged.drop(['date'], axis=1)\n",
    "df_merged['country_2'] = df_merged['country']\n",
    "df_merged = df_merged.rename(columns={\"new_date\":\"date\"})\n",
    "\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_all.csv\")\n",
    "df_merged.to_csv(output_path)\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date  2020-02-27 20:15:20.515183\n",
      "Start Date 2020-01-26 00:00:00\n",
      "2020-01-26\n",
      "2020-01-27\n",
      "2020-01-28\n",
      "2020-01-29\n",
      "2020-01-30\n",
      "2020-01-31\n",
      "2020-02-01\n",
      "2020-02-02\n",
      "2020-02-03\n",
      "2020-02-04\n",
      "2020-02-05\n",
      "2020-02-06\n",
      "2020-02-07\n",
      "2020-02-08\n",
      "2020-02-09\n",
      "2020-02-10\n",
      "2020-02-11\n",
      "2020-02-12\n",
      "2020-02-13\n",
      "2020-02-14\n",
      "2020-02-15\n",
      "2020-02-16\n",
      "2020-02-17\n",
      "2020-02-18\n",
      "2020-02-19\n",
      "2020-02-20\n",
      "2020-02-21\n",
      "2020-02-22\n",
      "2020-02-23\n",
      "2020-02-24\n",
      "2020-02-25\n",
      "2020-02-26\n",
      "2020-02-27\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.now()\n",
    "print(\"Current Date \",current_date)\n",
    "start_date = datetime.strptime('2020-01-26', \"%Y-%m-%d\")\n",
    "print(\"Start Date\", start_date)\n",
    "# end_date = start_date + timedelta(days=10)\n",
    "# print(end_date)\n",
    "\n",
    "while current_date >= start_date:\n",
    "    pass_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    print(pass_date)\n",
    "    create_geojson(pass_date)\n",
    "    start_date = start_date + timedelta(days=1)\n",
    "\n",
    "# create_geojson('2020-02-26')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
