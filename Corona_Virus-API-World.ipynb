{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import pprint\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geojson(date):\n",
    "    df_countries_by_day = df_merged[(df_merged.date==date)]\n",
    "    df_data = df_countries_by_day.groupby(['country','country_2']).agg({'conf_count':'sum', 'cured_count':'sum', 'dead_count':'sum'}).reset_index()\n",
    "    df_data = df_data.set_index('country')\n",
    "                                              \n",
    "    json_df = pd.read_json('static/world_geojsons/world.json', encoding='UTF-8')\n",
    "    json_df_feat = pd.DataFrame(json_df.features)\n",
    "\n",
    "    geo_dict = {}\n",
    "    geo_string = \"\"\n",
    "\n",
    "    for index, row in json_df_feat.iterrows():\n",
    "#         print(row['features']['properties']['ADMIN'])\n",
    "        try:\n",
    "            str_feat_1 = (\"{\\\"type\\\": \\\"Feature\\\",\")\n",
    "\n",
    "            prop_name = row['features']['properties']['ADMIN']\n",
    "            prop_american_name = df_data.loc[prop_name,\"country_2\"]\n",
    "            prop_confirmedCount = df_data.loc[prop_name,\"conf_count\"]\n",
    "            prop_suspectedCount = 0\n",
    "            prop_curedCount = df_data.loc[prop_name,\"cured_count\"]\n",
    "            prop_deadCount = df_data.loc[prop_name,\"dead_count\"]    \n",
    "            prop_date = date\n",
    "\n",
    "            str_prop_double_quotes = str(row['features']['properties'])\n",
    "            str_prop_double_quotes = str_prop_double_quotes.replace(\"\\'\",\"\\\"\")\n",
    "\n",
    "            str_prop_1 = (\"\\\"properties\\\" : \" + str_prop_double_quotes + \"\\\",\")[:-3]\n",
    "            str_prop_2 = (\",\\\"american_name\\\" : \\\"\" + prop_american_name + \"\\\",\")\n",
    "            str_prop_3 = (\"\\\"confirmedCount\\\" : \\\"\" + str(prop_confirmedCount) + \"\\\",\")\n",
    "            str_prop_4 = (\"\\\"suspectedCount\\\" : \\\"\" + str(prop_suspectedCount) + \"\\\",\")\n",
    "            str_prop_5 = (\"\\\"curedCount\\\" : \\\"\" + str(prop_curedCount) + \"\\\",\")\n",
    "            str_prop_6 = (\"\\\"deadCount\\\" : \\\"\" + str(prop_deadCount) + \"\\\",\")\n",
    "            str_prop_7 = (\"\\\"date\\\" : \\\"\" + prop_date + \"\\\"},\")\n",
    "\n",
    "            str_prop_all  = str_prop_1 + str_prop_2 + str_prop_3 + str_prop_4 + str_prop_5 + str_prop_6 + str_prop_7\n",
    "#             print(str_prop_all)\n",
    "            str_geom_1 = (\"\\\"geometry\\\":\" + str(row['features']['geometry']) + \"},\")\n",
    "            str_geom_1 = str_geom_1.replace(\"\\'\",\"\\\"\")\n",
    "#             print(str_geom_1)\n",
    "\n",
    "            str_for_each_province = (str_feat_1)+(str_prop_all)+(str_geom_1)\n",
    "#             print(str_for_each_province)\n",
    "            geo_string = geo_string + (str_for_each_province)\n",
    "        except:\n",
    "            geo_string = geo_string\n",
    "    \n",
    "    pre_fix = \"{\\\"type\\\": \\\"FeatureCollection\\\", \\\"features\\\": [\"\n",
    "    post_fix = \"]}\"\n",
    "\n",
    "    total_string = pre_fix + geo_string[:-1] + post_fix\n",
    "\n",
    "#     print(total_string)\n",
    "    output_path = os.path.join(\"static/world_geojsons\", date + \".json\")\n",
    "    with open(output_path, \"w\", encoding='UTF-8') as text_file:\n",
    "        text_file.write(total_string)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/22/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/24/20</th>\n",
       "      <th>2/25/20</th>\n",
       "      <th>2/26/20</th>\n",
       "      <th>2/27/20</th>\n",
       "      <th>2/28/20</th>\n",
       "      <th>2/29/20</th>\n",
       "      <th>3/1/20</th>\n",
       "      <th>3/2/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>413</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long  1/22/20  1/23/20  \\\n",
       "0          Anhui  Mainland China  31.8257  117.2264        1        9   \n",
       "1        Beijing  Mainland China  40.1824  116.4142       14       22   \n",
       "2      Chongqing  Mainland China  30.0572  107.8740        6        9   \n",
       "3         Fujian  Mainland China  26.0789  117.9874        1        5   \n",
       "4          Gansu  Mainland China  36.0611  103.8343        0        2   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/22/20  2/23/20  2/24/20  \\\n",
       "0       15       39       60       70  ...      989      989      989   \n",
       "1       36       41       68       80  ...      399      399      399   \n",
       "2       27       57       75      110  ...      573      575      576   \n",
       "3       10       18       35       59  ...      293      293      293   \n",
       "4        2        4        7       14  ...       91       91       91   \n",
       "\n",
       "   2/25/20  2/26/20  2/27/20  2/28/20  2/29/20  3/1/20  3/2/20  \n",
       "0      989      989      989      990      990     990     990  \n",
       "1      400      400      410      410      411     413     414  \n",
       "2      576      576      576      576      576     576     576  \n",
       "3      294      294      296      296      296     296     296  \n",
       "4       91       91       91       91       91      91      91  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data from 3 different data source\n",
    "confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv'\n",
    "df_confirmed = pd.read_csv(confirmed_url)\n",
    "cured_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'\n",
    "df_cured = pd.read_csv(cured_url)\n",
    "death_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv'\n",
    "df_death = pd.read_csv(death_url)\n",
    "\n",
    "df_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>36.0611</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Lat      Long     Date  Value   new_date\n",
       "0          Anhui  Mainland China  31.8257  117.2264  1/22/20      1 2020-01-22\n",
       "1        Beijing  Mainland China  40.1824  116.4142  1/22/20     14 2020-01-22\n",
       "2      Chongqing  Mainland China  30.0572  107.8740  1/22/20      6 2020-01-22\n",
       "3         Fujian  Mainland China  26.0789  117.9874  1/22/20      1 2020-01-22\n",
       "4          Gansu  Mainland China  36.0611  103.8343  1/22/20      0 2020-01-22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unique rows by moving date column to row level for all Confirmed cases\n",
    "df_confirmed_long = df_confirmed.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_confirmed_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_confirmed_original.csv\")\n",
    "df_confirmed.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Cured cases\n",
    "df_cured_long = df_cured.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_cured_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_cured_original.csv\")\n",
    "df_cured.to_csv(output_path)\n",
    "\n",
    "# Create unique rows by moving date column to row level for all Death cases\n",
    "df_death_long = df_death.melt(id_vars=[\"Province/State\", \"Country/Region\",\"Lat\",\"Long\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "df_death_long.head()\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_death_original.csv\")\n",
    "df_death.to_csv(output_path)\n",
    "\n",
    "df_confirmed_long.head()\n",
    "df_confirmed_long[\"new_date\"] = pd.to_datetime(df_confirmed_long['Date'])\n",
    "\n",
    "df_confirmed_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Province/State isn't filled, use the country value instead\n",
    "\n",
    "df_confirmed_long[\"Province/State\"].fillna(df_confirmed_long[\"Country/Region\"], inplace=True)\n",
    "df_confirmed_long = df_confirmed_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\", \"Date\":\"date\", \"Value\": \"conf_count\"})\n",
    "\n",
    "df_cured_long[\"Province/State\"].fillna(df_cured_long[\"Country/Region\"], inplace=True)\n",
    "df_cured_long = df_cured_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"cured_count\"})\n",
    "\n",
    "df_death_long[\"Province/State\"].fillna(df_death_long[\"Country/Region\"], inplace=True)\n",
    "df_death_long = df_death_long.rename(columns={\"Province/State\":\"american_name\", \"Country/Region\":\"country\", \"Lat\":\"lat\",\"Long\":\"long\",\"Date\":\"date\", \"Value\": \"dead_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure country names in both files match\n",
    "df_confirmed_long.loc[(df_confirmed_long.country == 'Mainland China'),'country']='China'\n",
    "df_confirmed_long.loc[(df_confirmed_long.country == 'US'),'country']='United States of America'\n",
    "df_confirmed_long = df_confirmed_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_cured_long.loc[(df_cured_long.country == 'Mainland China'),'country']='China'\n",
    "df_cured_long.loc[(df_cured_long.country == 'US'),'country']='United States of America'\n",
    "df_cured_long = df_cured_long.set_index(['date', 'american_name'])\n",
    "\n",
    "df_death_long.loc[(df_death_long.country == 'Mainland China'),'country']='China'\n",
    "df_death_long.loc[(df_death_long.country == 'US'),'country']='United States of America'\n",
    "df_death_long = df_death_long.set_index(['date', 'american_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all 3 datasets\n",
    "df_merged = pd.merge(df_confirmed_long, df_cured_long, how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_death_long,how='left', on=['date', 'american_name', 'country','lat','long'])\n",
    "df_merged = df_merged.reset_index()\n",
    "df_merged = df_merged.drop(['date'], axis=1)\n",
    "df_merged['country_2'] = df_merged['country']\n",
    "df_merged = df_merged.rename(columns={\"new_date\":\"date\"})\n",
    "\n",
    "output_path = os.path.join(\"static/world_data\", \"df_world_all.csv\")\n",
    "df_merged.to_csv(output_path)\n",
    "\n",
    "df_merged = df_merged[df_merged['conf_count']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american_name</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>conf_count</th>\n",
       "      <th>date</th>\n",
       "      <th>cured_count</th>\n",
       "      <th>dead_count</th>\n",
       "      <th>country_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>23.3417</td>\n",
       "      <td>113.4244</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>Placer County, CA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>39.0916</td>\n",
       "      <td>-120.8039</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>37.5630</td>\n",
       "      <td>-122.3255</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>Sarasota, FL</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>27.3364</td>\n",
       "      <td>-82.5307</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>Sonoma County, CA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>38.5780</td>\n",
       "      <td>-122.9888</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>Umatilla, OR</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>45.7750</td>\n",
       "      <td>-118.7606</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3048 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          american_name                   country      lat      long  \\\n",
       "0                 Anhui                     China  31.8257  117.2264   \n",
       "1               Beijing                     China  40.1824  116.4142   \n",
       "2             Chongqing                     China  30.0572  107.8740   \n",
       "3                Fujian                     China  26.0789  117.9874   \n",
       "5             Guangdong                     China  23.3417  113.4244   \n",
       "...                 ...                       ...      ...       ...   \n",
       "5817  Placer County, CA  United States of America  39.0916 -120.8039   \n",
       "5818      San Mateo, CA  United States of America  37.5630 -122.3255   \n",
       "5819       Sarasota, FL  United States of America  27.3364  -82.5307   \n",
       "5820  Sonoma County, CA  United States of America  38.5780 -122.9888   \n",
       "5821       Umatilla, OR  United States of America  45.7750 -118.7606   \n",
       "\n",
       "      conf_count       date  cured_count  dead_count                 country_2  \n",
       "0              1 2020-01-22            0           0                     China  \n",
       "1             14 2020-01-22            0           0                     China  \n",
       "2              6 2020-01-22            0           0                     China  \n",
       "3              1 2020-01-22            0           0                     China  \n",
       "5             26 2020-01-22            0           0                     China  \n",
       "...          ...        ...          ...         ...                       ...  \n",
       "5817           1 2020-03-02            0           0  United States of America  \n",
       "5818           1 2020-03-02            0           0  United States of America  \n",
       "5819           1 2020-03-02            0           0  United States of America  \n",
       "5820           1 2020-03-02            0           0  United States of America  \n",
       "5821           1 2020-03-02            0           0  United States of America  \n",
       "\n",
       "[3048 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# last_date = df_merged['date'].max()\n",
    "# print(last_date)\n",
    "\n",
    "#### Keep for when having to rebuild all geojson. Go back to 2020-01-22\n",
    "last_date = last_date + timedelta(days=-2)\n",
    "print(last_date_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date  2020-03-03 06:31:22.188522\n",
      "Yesterday:  2020-03-02 06:31:22.188522\n",
      "Start Date 2020-02-29 00:00:00\n",
      "2020-02-29\n",
      "2020-03-01\n",
      "2020-03-02\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.now()\n",
    "print(\"Current Date \",current_date)\n",
    "yesterday = current_date+ timedelta(days=-1)\n",
    "print(\"Yesterday: \",yesterday)\n",
    "\n",
    "start_date = last_date\n",
    "print(\"Start Date\", start_date)\n",
    "\n",
    "while yesterday > start_date:\n",
    "    pass_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    print(pass_date)\n",
    "    create_geojson(pass_date)\n",
    "    start_date = start_date + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
